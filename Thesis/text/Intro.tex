Although formal logic can be traced back to Aristotle, most of the
groundbreaking work was done around the end of the 19th and early 20th centuries:
the specification of propositional calculus; what we now know as predicate logic and other developments. The quest for bootstrapping mathematics, that is, formalizing mathematics in formal logic, was
being pursued by many. A notorious attempt was made by Russel and Whitehead in \emph{Principia Mathematica}, \cite{Whitehead1912}, where they believed that all mathematical truths
could be derived from inference rules and axioms, therefore opening up the question of automated reasoning. Yet, in 1931, Kurt G\"{o}del published his famous first and second incompleteness theorems. In a (very small) nutshell, they state that there are some truths that are not provable, regardless of the axiomatic system chosen. This question was further addressed by Alonzo Church and Alan Turing, in the late 1930s. This is when a definite notion of computability first arose (in fact they gave two, independent, definitions).

Armed with a formal notion of computation, mathematicians could finally start to explore this newly
founded world, which we call Computing Science nowadays. Problems started to be categorized in 
different classes due to their complexity. In fact, some problems could now be proven to be \emph{unsolvable}.
Whenever we encounter such problem, we must work with approximations and subproblems that we
know we can compute a solution for. 

Given a formula in a logic system, the question of whether or not such a formula is true can vary from trivial to impossible. The simplest case is, of course, propositional logic, where validity is decidable but not at all that interesting
for software verification in general. We need more expressive formal systems in order to encode software specifications, as they usually involve quantification or even modal aspects.  A \emph{holy grail} for formal verification would be the construction of a fully automatic theorem prover, which is very hard (if not impossible) to achieve. Instead, whenever the task requires an expressive system, we could only provide a guiding hand to our fellow mathematicians. This is what we call a \emph{Proof Assistant}.

Proof Assistants are highly dependent on which logic they can understand. With the development of more
expressive logics, comes the development of better proof assistants. Such tools are used to mitigate
simple mistakes, automate trivial operations, and make sure the mathematician is not working
on any incongruence. Besides the obvious verification of proofs, a proof assistant also opens up
a lot of room for proof automation. By automating mechanical tasks in the development of 
critical software or models we can help the programmer to focus on what is really important
rather than making he write boilerplate code that is mechanical in nature.

As we said above, proof assistants depend on the logic they run on top of. Some of them,
however, support some form of meta programming. That is, we can write programs that generate
programs. This is achieved by having the programming language itself as a first class datatype.
Examples include LISP and Prolog. One of the goals of this project is to explore how can
we exploit such feature to automate the repetitive task of rewriting terms for other,
proven to be equal, terms.

The tool of choice for this project is the Agda language, developed at Chalmers \cite{norell07}. Agda uses a intensional
variant of Martin-L\"{o}f's theory of types and provides a nice interactive construction feature. After
the Curry-Howard isomorphism \cite{Howard01}, interactive program construction and assisted theorem proving are essentially
the same thing. The usual routine of an Agda programmer is to write some code, with some \emph{holes} for
the unfinished parts, and then ask the typechecker which types should such \emph{holes} have. This is done
interactively. Yet, trivial operations to write on paper usually require additional code
for discharging in Agda. One such example is its failure to automatically recognize $i + 1$ and
$1 + i$ as returning the same value. The usual strategy is to rewrite this subterm of our goal
using a commutativity proof for $+$. 

Small rewrites are quite simple to perform using the \K{rewrite} keyword. If we need to perform
equational reasoning over complex formulas, though, we are going to need to specify the
substitutions manually in order to apply a theorem to a subterm. The main objective of this project is
to work around this limitation and provide a smarter rewriting mechanism for Agda. Our main 
case study is the equational proofs for relational algebra \cite{Bird97}, which also involves
the construction of a relational algebra library suited for rewriting.
